% ============================================================================
% Passive Learning
% ============================================================================

@inproceedings{lei2016rationalizing,
  title={Rationalizing Neural Predictions},
  author={Lei, Tao and Barzilay, Regina and Jaakkola, Tommi},
  booktitle={Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing},
  pages={107--117},
  year={2016}
}

@inproceedings{ross2017right,
  title={Right for the right reasons: training differentiable models by constraining their explanations},
  author={Ross, Andrew Slavin and Hughes, Michael C and Doshi-Velez, Finale},
  booktitle={Proceedings of the 26th International Joint Conference on Artificial Intelligence},
  pages={2662--2670},
  year={2017}
}

@inproceedings{wang2018learning,
  title={Learning credible models},
  author={Wang, Jiaxuan and Oh, Jeeheh and Wang, Haozhu and Wiens, Jenna},
  booktitle={Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={2417--2426},
  year={2018}
}

@inproceedings{bao2018deriving,
  title={Deriving Machine Attention from Human Rationales},
  author={Bao, Yujia and Chang, Shiyu and Yu, Mo and Barzilay, Regina},
  booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
  pages={1903--1913},
  year={2018}
}

@inproceedings{hind2019ted,
  title={TED: Teaching AI to explain its decisions},
  author={Hind, Michael and Wei, Dennis and Campbell, Murray and Codella, Noel CF and Dhurandhar, Amit and Mojsilovi{\'c}, Aleksandra and Natesan Ramamurthy, Karthikeyan and Varshney, Kush R},
  booktitle={Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society},
  pages={123--129},
  year={2019}
}

@inproceedings{strout2019human,
  title={Do Human Rationales Improve Machine Explanations?},
  author={Strout, Julia and Zhang, Ye and Mooney, Raymond},
  booktitle={Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP},
  pages={56--62},
  year={2019}
}

@article{erion2019improving,
  title={Improving performance of deep learning models with axiomatic attribution priors and expected gradients},
  author={Erion, G and Janizek, JD and Sturmfels, P and Lundberg, S and Lee, SI},
  journal={arXiv preprint arXiv:1906.10670},
  year={2019}
}

@article{pedapati2020learning,
  title={Learning Global Transparent Models Consistent with Local Contrastive Explanations},
  author={Pedapati, Tejaswini and Balakrishnan, Avinash and Shanmugam, Karthikeyan and Dhurandhar, Amit},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@inproceedings{rieger2020interpretations,
  title={Interpretations are useful: penalizing explanations to align neural networks with prior knowledge},
  author={Rieger, Laura and Singh, Chandan and Murdoch, William and Yu, Bin},
  booktitle={International Conference on Machine Learning},
  pages={8116--8126},
  year={2020},
  organization={PMLR}
}

@inproceedings{jain2020learning,
  title={Learning to Faithfully Rationalize by Construction},
  author={Jain, Sarthak and Wiegreffe, Sarah and Pinter, Yuval and Wallace, Byron C},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={4459--4473},
  year={2020}
}

@article{schneider2020reflective,
  title={Reflective-Net: Learning from Explanations},
  author={Schneider, Johannes and Vlachos, Michalis},
  journal={arXiv preprint arXiv:2011.13986},
  year={2020}
}

@article{hase2021can,
  title={When Can Models Learn From Explanations? A Formal Framework for Understanding the Roles of Explanation Data},
  author={Hase, Peter and Bansal, Mohit},
  journal={arXiv preprint arXiv:2102.02201},
  year={2021}
}

@article{lage2020learning,
  title={Learning Interpretable Concept-Based Models with Human Feedback},
  author={Lage, Isaac and Doshi-Velez, Finale},
  journal={arXiv preprint arXiv:2012.02898},
  year={2020}
}

@article{setzu2021glocalx,
  title={GLocalX-From Local to Global Explanations of Black Box AI Models},
  author={Setzu, Mattia and Guidotti, Riccardo and Monreale, Anna and Turini, Franco and Pedreschi, Dino and Giannotti, Fosca},
  journal={Artificial Intelligence},
  volume={294},
  pages={103457},
  year={2021},
  publisher={Elsevier}
}

@inproceedings{bahadori2021debiasing,
  title={Debiasing Concept-based Explanations with Causal Analysis},
  author={Bahadori, Mohammad Taha and Heckerman, David},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@inproceedings{raghu2021teaching,
  title={Teaching with Commentaries},
  author={Raghu, Aniruddh and Raghu, Maithra and Kornblith, Simon and Duvenaud, David and Hinton, Geoffrey},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@article{zhang2021explain,
  title={Explain and Predict, and then Predict again},
  author={Zhang, Zijian and Rudra, Koustav and Anand, Avishek},
  journal={arXiv preprint arXiv:2101.04109},
  year={2021}
}

@article{barnett2021iaia,
  title={IAIA-BL: A Case-based Interpretable Deep Learning Model for Classification of Mass Lesions in Digital Mammography},
  author={Barnett, Alina Jade and Schwartz, Fides Regina and Tao, Chaofan and Chen, Chaofan and Ren, Yinhao and Lo, Joseph Y and Rudin, Cynthia},
  journal={arXiv preprint arXiv:2103.12308},
  year={2021}
}

@article{chrysostomou2021enjoy,
  title={Enjoy the Salience: Towards Better Transformer-based Faithful Explanations with Word Salience},
  author={Chrysostomou, George and Aletras, Nikolaos},
  journal={arXiv preprint arXiv:2108.13759},
  year={2021}
}


% ============================================================================
% Interactive Learning
% ============================================================================

@inproceedings{kulesza2015principles,
  title={Principles of explanatory debugging to personalize interactive machine learning},
  author={Kulesza, Todd and Burnett, Margaret and Wong, Weng-Keen and Stumpf, Simone},
  booktitle={Proceedings of the 20th international conference on intelligent user interfaces},
  pages={126--137},
  year={2015}
}

@inproceedings{teso2019explanatory,
  title={Explanatory interactive machine learning},
  author={Teso, Stefano and Kersting, Kristian},
  booktitle={Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society},
  pages={239--245},
  year={2019}
}

@inproceedings{selvaraju2019taking,
  title={Taking a hint: Leveraging explanations to make vision and language models more grounded},
  author={Selvaraju, Ramprasaath R and Lee, Stefan and Shen, Yilin and Jin, Hongxia and Ghosh, Shalini and Heck, Larry and Batra, Dhruv and Parikh, Devi},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2591--2600},
  year={2019}
}

@inproceedings{teso2019toward,
  title={Toward Faithful Explanatory Active Learning with Self-explainable Neural Nets},
  author={Teso, Stefano},
  booktitle={Proceedings of the Workshop on Interactive Adaptive Learning (IAL 2019)},
  pages={4--16},
  year={2019}
}

@article{schramowski2020making,
  title={Making deep neural networks right for the right scientific reasons by interacting with their explanations},
  author={Schramowski, Patrick and Stammer, Wolfgang and Teso, Stefano and Brugger, Anna and Herbert, Franziska and Shao, Xiaoting and Luigs, Hans-Georg and Mahlein, Anne-Katrin and Kersting, Kristian},
  journal={Nature Machine Intelligence},
  volume={2},
  number={8},
  pages={476--486},
  year={2020},
  publisher={Nature Publishing Group}
}

@article{sokol2020one,
  title={One explanation does not fit all},
  author={Sokol, Kacper and Flach, Peter},
  journal={KI-K{\"u}nstliche Intelligenz},
  pages={1--16},
  year={2020},
  publisher={Springer}
}

@inproceedings{lertvittayakumjorn2020find,
  title={FIND: human-in-the-loop debugging deep text classifiers},
  author={Lertvittayakumjorn, Piyawat and Specia, Lucia and Toni, Francesca},
  booktitle={Conference on Empirical Methods in Natural Language Processing},
  pages={332--348},
  year={2020}
}

@inproceedings{ciravegna2020human,
  title={Human-driven FOL explanations of deep learning},
  author={Ciravegna, Gabriele and Giannini, Francesco and Gori, Marco and Maggini, Marco and Melacci, Stefano},
  booktitle={Twenty-Ninth International Joint Conference on Artificial Intelligence and Seventeenth Pacific Rim International Conference on Artificial Intelligence},
  pages={2234--2240},
  year={2020},
  organization={International Joint Conferences on Artificial Intelligence Organization}
}

@article{popordanoska2020machine,
  title={Machine guides, human supervises: Interactive learning with global explanations},
  author={Popordanoska, Teodora and Kumar, Mohit and Teso, Stefano},
  journal={arXiv preprint arXiv:2009.09723},
  year={2020}
}

@inproceedings{stammer2021right,
  title={Right for the Right Concept: Revising Neuro-Symbolic Concepts by Interacting with their Explanations},
  author={Stammer, Wolfgang and Schramowski, Patrick and Kersting, Kristian},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3619--3629},
  year={2021}
}

@inproceedings{shao2021right,
  title={Right for Better Reasons: Training Differentiable Models by Constraining their Influence Function},
  author={Shao, Xiaoting and Skryagin, Arseny and Schramowski, P and Stammer, W and Kersting, Kristian},
  booktitle={Proceedings of Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI)},
  year={2021}
}

@inproceedings{daly2021user,
  title={User Driven Model Adjustment via Boolean Rule Explanations},
  author={Daly, Elizabeth M and Mattetti, Massimiliano and Alkan, {\"O}znur and Nair, Rahul},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={7},
  pages={5896--5904},
  year={2021}
}

@article{ghai2021explainable,
  title={Explainable active learning (xal) toward ai explanations as interfaces for machine teachers},
  author={Ghai, Bhavya and Liao, Q Vera and Zhang, Yunfeng and Bellamy, Rachel and Mueller, Klaus},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={4},
  number={CSCW3},
  pages={1--28},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{behrens2021bandits,
  title={Bandits for Learning to Explain from Explanations},
  author={Behrens, Freya and Teso, Stefano and Mottin, Davide},
  journal={arXiv preprint arXiv:2102.03815},
  year={2021}
}

@inproceedings{heo2020cost,
  title={Cost-effective Interactive Attention Learning with Neural Attention Processes},
  author={Heo, Jay and Park, Junhyeon and Jeong, Hyewon and Kim, Kwang Joon and Lee, Juho and Yang, Eunho and Hwang, Sung Ju},
  booktitle={International Conference on Machine Learning},
  pages={4228--4238},
  year={2020},
  organization={PMLR}
}

@article{zylberajch2021hildif,
  title={HILDIF: Interactive Debugging of NLI Models Using Influence Functions},
  author={Zylberajch, Hugo and Lertvittayakumjorn, Piyawat and Toni, Francesca},
  journal={Workshop on Interactive Learning for Natural Language Processing},
  pages={1},
  year={2021}
}

@article{yao2021refining,
  title={Refining Neural Networks with Compositional Explanations},
  author={Yao, Huihan and Chen, Ying and Ye, Qinyuan and Jin, Xisen and Ren, Xiang},
  journal={arXiv preprint arXiv:2103.10415},
  year={2021}
}

@article{teso2021interactive,
  title={Interactive Label Cleaning with Example-based Explanations},
  author={Teso, Stefano and Bontempelli, Andrea and Giunchiglia, Fausto and Passerini, Andrea},
  journal={arXiv preprint arXiv:2106.03922},
  year={2021}
}


% ============================================================================
% Reinforcement Learning
% ============================================================================

@article{guan2020explanation,
  title={Explanation augmented feedback in human-in-the-loop reinforcement learning},
  author={Guan, Lin and Verma, Mudit and Kambhampati, Subbarao},
  journal={arXiv preprint arXiv:2006.14804},
  year={2020}
}

@inproceedings{tulli2020learning,
  title={Learning from explanations and demonstrations: A pilot study},
  author={Tulli, Silvia and Wallk{\"o}tter, Sebastian and Paiva, Ana and Melo, Francisco S and Chetouani, Mohamed},
  booktitle={2nd Workshop on Interactive Natural Language Technology for Explainable Artificial Intelligence},
  pages={61--66},
  year={2020}
}


% ============================================================================
% Model Distillation
% ============================================================================

@inproceedings{milli2019model,
  title={Model reconstruction from model explanations},
  author={Milli, Smitha and Schmidt, Ludwig and Dragan, Anca D and Hardt, Moritz},
  booktitle={Proceedings of the Conference on Fairness, Accountability, and Transparency},
  pages={1--9},
  year={2019}
}

@article{pruthi2020evaluating,
  title={Evaluating Explanations: How much do explanations from the teacher aid students?},
  author={Pruthi, Danish and Dhingra, Bhuwan and Soares, Livio Baldini and Collins, Michael and Lipton, Zachary C and Neubig, Graham and Cohen, William W},
  journal={arXiv preprint arXiv:2012.00893},
  year={2020}
}


% ============================================================================
% Regularization without Supervision
% ============================================================================

@inproceedings{ross2018improving,
  title={Improving the adversarial robustness and interpretability of deep neural networks by regularizing their input gradients},
  author={Ross, Andrew and Doshi-Velez, Finale},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  number={1},
  year={2018}
}

@inproceedings{alvarez2018towards,
  title={Towards robust interpretability with self-explaining neural networks},
  author={Alvarez-Melis, David and Jaakkola, Tommi S},
  booktitle={Proceedings of the 32nd International Conference on Neural Information Processing Systems},
  pages={7786--7795},
  year={2018}
}

@inproceedings{wu2018beyond,
  title={Beyond sparsity: Tree regularization of deep models for interpretability},
  author={Wu, Mike and Hughes, Michael and Parbhoo, Sonali and Zazzi, Maurizio and Roth, Volker and Doshi-Velez, Finale},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  number={1},
  year={2018}
}

@inproceedings{wu2020regional,
  title={Regional tree regularization for interpretability in deep neural networks},
  author={Wu, Mike and Parbhoo, Sonali and Hughes, Michael and Kindle, Ryan and Celi, Leo and Zazzi, Maurizio and Roth, Volker and Doshi-Velez, Finale},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={04},
  pages={6413--6421},
  year={2020}
}

@inproceedings{plumb2020regularizing,
  title={Regularizing black-box models for improved interpretability},
  author={Plumb, Gregory and Al-Shedivat, Maruan and Cabrera, {\'A}ngel Alexander and Perer, Adam and Xing, Eric and Talwalkar, Ameet},
  booktitle={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@inproceedings{pillai2021explainable,
  title={Explainable Models with Consistent Interpretations},
  author={Pillai, Vipin and Pirsiavash, Hamed},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2021},
}

@inproceedings{han2021explanation,
  title={Explanation Consistency Training: Facilitating Consistency-Based Semi-Supervised Learning with Interpretability},
  author={Han, Tao and Tu, Wei-Wei and Li, Yu-Feng},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2021},
}

@article{halliwell2020trustworthy,
  title={Trustworthy convolutional neural networks: A gradient penalized-based approach},
  author={Halliwell, Nicholas and Lecue, Freddy},
  journal={arXiv preprint arXiv:2009.14260},
  year={2020}
}


% ============================================================================
% Machine Teaching
% ============================================================================

@inproceedings{su2017interpretable,
  title={Interpretable Machine Teaching via Feature Feedback},
  author={Su, Shihan and Chen, Yuxin and Mac Aodha, Oisin and Perona, Pietro and Yue, Yisong},
  booktitle={NIPS'17 Workshop on Teaching Machines, Robots, and Humans},
  year={2017}
}


% ============================================================================
% Applications
% ============================================================================

@article{sefcik2021improving,
  title={Improving a neural network model by explanation-guided training for glioma classification based on MRI data},
  author={Sefcik, Frantisek and Benesova, Wanda},
  journal={arXiv preprint arXiv:2107.02008},
  year={2021}
}


% ============================================================================
% Related Works
% ============================================================================

% Explanation-based Learning

@article{mitchell1986explanation,
  title={Explanation-based generalization: A unifying view},
  author={Mitchell, Tom M and Keller, Richard M and Kedar-Cabelli, Smadar T},
  journal={Machine learning},
  volume={1},
  number={1},
  pages={47--80},
  year={1986},
  publisher={Springer}
}

@article{dejong1986explanation,
  title={Explanation-based learning: An alternative view},
  author={DeJong, Gerald and Mooney, Raymond},
  journal={Machine learning},
  volume={1},
  number={2},
  pages={145--176},
  year={1986},
  publisher={Springer}
}

@article{ellman1989explanation,
  title={Explanation-based learning: A survey of programs and perspectives},
  author={Ellman, Thomas},
  journal={ACM Computing Surveys (CSUR)},
  volume={21},
  number={2},
  pages={163--221},
  year={1989},
  publisher={ACM New York, NY, USA}
}

@inproceedings{kimmig2007probabilistic,
  title={Probabilistic explanation based learning},
  author={Kimmig, Angelika and De Raedt, Luc and Toivonen, Hannu},
  booktitle={European Conference on Machine Learning},
  pages={176--187},
  year={2007},
  organization={Springer}
}

% Injecting invariances / feature constraints into models

@inproceedings{simard1991tangent,
  title={Tangent prop-a formalism for specifying selected invariances in an adaptive network},
  author={Simard, Patrice and Victorri, Bernard and LeCun, Yann and Denker, John S},
  booktitle={NIPS},
  volume={91},
  pages={895--903},
  year={1991}
}

@article{decoste2002training,
  title={Training invariant support vector machines},
  author={DeCoste, Dennis and Sch{\"o}lkopf, Bernhard},
  journal={Machine learning},
  volume={46},
  number={1},
  pages={161--190},
  year={2002},
  publisher={Springer}
}

@inproceedings{small2011constrained,
  title={The constrained weight space svm: learning with ranked features},
  author={Small, Kevin and Wallace, Byron C and Brodley, Carla E and Trikalinos, Thomas A},
  booktitle={Proceedings of the 28th International Conference on International Conference on Machine Learning},
  pages={865--872},
  year={2011}
}

% Dual label-feature feedback

@article{raghavan2006active,
  title={Active learning with feedback on features and instances},
  author={Raghavan, Hema and Madani, Omid and Jones, Rosie},
  journal={The Journal of Machine Learning Research},
  volume={7},
  pages={1655--1686},
  year={2006},
  publisher={JMLR. org}
}

@inproceedings{raghavan2007interactive,
  title={An interactive algorithm for asking and incorporating feature feedback into support vector machines},
  author={Raghavan, Hema and Allan, James},
  booktitle={Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval},
  pages={79--86},
  year={2007}
}

@inproceedings{druck2008learning,
  title={Learning from labeled features using generalized expectation criteria},
  author={Druck, Gregory and Mann, Gideon and McCallum, Andrew},
  booktitle={Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval},
  pages={595--602},
  year={2008}
}

@inproceedings{druck2009active,
  title={Active learning by labeling features},
  author={Druck, Gregory and Settles, Burr and McCallum, Andrew},
  booktitle={Proceedings of the 2009 conference on Empirical methods in natural language processing},
  pages={81--90},
  year={2009}
}

@inproceedings{attenberg2010unified,
  title={A unified approach to active dual supervision for labeling features and examples},
  author={Attenberg, Josh and Melville, Prem and Provost, Foster},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={40--55},
  year={2010},
  organization={Springer}
}

@inproceedings{settles2011closing,
  title={Closing the loop: Fast, interactive semi-supervised annotation with queries on features and instances},
  author={Settles, Burr},
  booktitle={Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing},
  pages={1467--1478},
  year={2011}
}

% Annotator Rationales

@inproceedings{zaidan2007using,
  title={Using “annotator rationales” to improve machine learning for text categorization},
  author={Zaidan, Omar and Eisner, Jason and Piatko, Christine},
  booktitle={Human language technologies 2007: The conference of the North American chapter of the association for computational linguistics; proceedings of the main conference},
  pages={260--267},
  year={2007}
}

@inproceedings{zaidan2008modeling,
  title={Modeling annotators: A generative approach to learning from annotator rationales},
  author={Zaidan, Omar and Eisner, Jason},
  booktitle={Proceedings of the 2008 conference on Empirical methods in natural language processing},
  pages={31--40},
  year={2008}
}

@inproceedings{sharma2015active,
  title={Active learning with rationales for text classification},
  author={Sharma, Manali and Zhuang, Di and Bilgic, Mustafa},
  booktitle={Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={441--451},
  year={2015}
}

% Critiquing in recommenders

@article{chen2012critiquing,
  title={Critiquing-based recommenders: survey and emerging trends},
  author={Chen, Li and Pu, Pearl},
  journal={User Modeling and User-Adapted Interaction},
  volume={22},
  number={1},
  pages={125--150},
  year={2012},
  publisher={Springer}
}

@inproceedings{teso2017coactive,
  title={Coactive critiquing: Elicitation of preferences and features},
  author={Teso, Stefano and Dragone, Paolo and Passerini, Andrea},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={31},
  number={1},
  year={2017}
}

% Gray-box models

@inproceedings{koh2020concept,
  title={Concept bottleneck models},
  author={Koh, Pang Wei and Nguyen, Thao and Tang, Yew Siang and Mussmann, Stephen and Pierson, Emma and Kim, Been and Liang, Percy},
  booktitle={International Conference on Machine Learning},
  pages={5338--5348},
  year={2020},
  organization={PMLR}
}
